---
layout: iros2019workshop
---


## Overview
In this workshop we will discuss the importance of uncertainty in deep learning for robotic applications. In addition, the workshop will host the 2nd [Probabilistic Object Detection challenge](object-detection), a new challenge that evaluates the ability of visual object detectors to accurately quantify their spatial and semantic uncertainty.

The workshop will provide tutorial-style talks that cover the state-of-the-art of uncertainty quantification in deep learning, specifically Bayesian and non-Bayesian approaches, spanning perception, world-modeling, decision making, and actions. Invited expert speakers will discuss the importance of uncertainty in deep learning for robotic perception, but also action. In addition the workshop will provide a forum to discuss novel and ongoing work in a variety of topics:

## Call for Contributions and Author Instructions

We welcome contributed papers addressing important questions of uncertainty and reliability of deep learning in robotics.  

### Topics of Interest
   * Uncertainty estimation in deep learning for robotic perception (e.g. object detection, instance segmentation)
   * Propagating uncertainty from perception to actions and decisions
   * Uncertainty in Reinforcement Learning
   * Deep learning in safety critical robotic applications
   * Deep learning in open-set conditions
   * The role of uncertainty for active learning, few-shot learning, and lifelong learning
   * Bayesian Deep Learning, deep probabilistic models
   * Adversarial attacks, safety, failure prediction

### Author Instructions
* Submissions can be made as either **short papers** (1-3 pages), or **regular papers** (4-6 pages plus references).
* Please [submit your paper through CMT](https://cmt3.research.microsoft.com/IUDLR2019), independent of its length. Please use the IROS paper format.
* All accepted papers will be presented at a poster session.
* Selected _regular papers_ (4-6 pages) are invited for an oral presentation and might be invited for a journal special issue we plan to organise.

## Participate in the Probabilistic Object Detection Competition
The workshop will host the [2nd Probabilistic Object Detection challenge](object-detection).

In contrast to conventional object detection, this challenge focuses on the probabilistic aspect of detections: a new metric evaluates both the **spatial and semantic uncertainty** of the object detector. Providing reliable uncertainty information is essential for robotics applications where actions triggered by erroneous but high-confidence perception can lead to catastrophic results.

## Important Dates

### For Contributed Papers
* **30 September:** Deadline for Contributed Paper [Submissions](https://cmt3.research.microsoft.com/IUDLR2019)
* **21 October:** Notification of Authors
* **28 October** Final Papers due
* **8 November 2019:** Workshop at IROS

### For Participation in the Probabilistic Object Detection Challenge
* **6 September:** [Evaluation Server](https://competitions.codalab.org/competitions/20597) for the [Probabilistic Object Detection challenge](object-detection) opens
* **8 October** Final Submissions to the Evaluation Server via [Codalab](https://competitions.codalab.org/competitions/20940)
* **10 October:** Deadline for Submitting Paper Explaining the Approach [Submissions](https://cmt3.research.microsoft.com/IUDLR2019)
* **14 October** Winner Announcements and Workshop Invitations
* **8 November 2019:** Workshop at IROS

## Confirmed Invited Speakers

to be announced

<!-- * Cesar Cadena, ETH Zürich
* Fabio Ramos, University of Sydney
* Di Feng, Bosch -->

## Schedule (8 November 2019)

to be announced

## Organisers

The Robotic Vision Challenges organisers are with the [Australian Centre for Robotic Vision](http://www.roboticvision.org) and [Google AI](http://ai.google/).

<div class="portrait_row">
<img class="col fith portrait" src="assets/img/niko.jpg"/>  
<img class="col fith portrait" src="assets/img/feras.jpg"/>
<img class="col fith portrait" src="assets/img/dimity.png"/>
<img class="col fith portrait" src="assets/img/anelia2.jpg"/>
</div>
<div class="col fith caption">
      <a href="http://www.nikosuenderhauf.info">Niko Sünderhauf</a><br>Queensland University of Technology
</div>
<div class="col fith caption">
      <a href="http://www.ferasdayoub.com">Feras Dayoub</a> <br>Queensland University of Technology
</div>
<div class="col fith caption">
      <a href="https://www.roboticvision.org/rv_person/dimity-miller/">Dimity Miller</a> <br> Queensland University of Technology
</div>
<div class="col fith caption">
      <a href="https://ai.google/research/people/AneliaAngelova">Anelia Angelova</a> <br> Google Brain
</div>


<div class="portrait_row">
<img class="col fith portrait" src="assets/img/david.jpg"/>
<img class="col fith portrait" src="assets/img/haoyang.jpg"/>
<img class="col fith portrait" src="assets/img/gustavo.jpg"/>  
<img class="col fith portrait" src="assets/img/TomDrummond.jpg"/>
</div>
<div class="col fith caption">
      <a href="https://sites.google.com/view/davidhallcv/home">David Hall</a> <br>Queensland University of Technology
</div>
<div class="col fith caption">
      <a href="https://staff.qut.edu.au/staff/haoyang.zhang.acrv">Haoyang Zhang</a> <br>Queensland University of Technology
</div>
<div class="col fith caption">
      <a href="https://cs.adelaide.edu.au/~carneiro/">Gustavo Carneiro</a> <br> University of Adelaide
</div>
<div class="col fith caption">
      <a href="https://www.monash.edu/engineering/tomdrummond">Tom Drummond</a> <br> Monash University
</div>


<br><br>

## Sponsors
<div style="display:flex; justify-content:center;">
<a href="http://www.roboticvision.org"><img style="height:120px;" src="assets/img/acrv.png"></a>
<!-- <a href="http://ai.google"><img style="margin-left:100px; height:100px" src="assets/img/google-logo.png"></a> -->
</div>
