---
layout: eccv2020workshop
---

## Overview
This workshop assesses current evaluation procedures for object detection, highlights their shortcomings and opens discussion for possible improvements.

Through a focus on evaluation using challenges, the object detection community has been able to quickly identify which methods are effective by examining performance metrics. However, as this technological boom progresses, it is important to assess whether our evaluation metrics and procedures adequately align with how object detection will be used in practical applications. **Quantitative results should be easily reconciled with a detector's performance in applied tasks.** This workshop provides a forum to discuss these ideas and evaluate whether current standards meet the needs of the object detection community.

In addition, this workshop is hosting the latest iteration of the Probabilistic Object Detection (PrOD) Challenge which requires competitors to estimate **semantic and spatial uncertainty**.

## Program: 28 August 2020

 * **09:00 - 09:10** -   Welcome, Introduction
 * **09:10 - 09:35** -   Invited Talk: Emre Akbas (Middle East Technical University)
 * **09:35 - 10:00** -   Invited Talk: Walter Scheirer (University of Notre Dame)
 * **10:00 - 10:30** -   Coffee Break
 * **10:30 - 10:55** -   Invited Talk: Larry Zitnick (Facebook AI Research)
 * **10:55 - 11:15** -   PrOD Challenge Overview and Discussion of Results
 * **11:15 - 11:30** -   Contributed Talk: (PrOD Challenge Winner) - T.B.A.
 * **11:30 - 11:35** -   Closing Remarks
 * **11:35 - 12:10** -   Poster Session


## Participate in the Competition
To **participate** in the competition, and for more information around the data and submission format, please go to our [Codalab Page](https://competitions.codalab.org/competitions/20597).

Our challenge requires participants to **detect objects in video** data (from high-fidelity simulation). As a novelty, our evaluation metric rewards accurate estimates of **spatial and semantic uncertainty** using probabilistic bounding boxes.
We developed a new [probability-based detection quality (PDQ)](https://arxiv.org/abs/1811.10800) evaluation measure for this challenge, please see the arxiv paper for more details.

Submissions must be accompanied by a **3-6 page paper** explaining the method and external data used. Please use the ECCV paper format (no need to keep it double-blind) and submission details will be provided closer to the date. Top performing submissions from the challenge will be invited to present their methods at the workshop.

<center>
<iframe width="560" height="315"  src="https://www.youtube.com/embed/6TR97EKUlaM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/LzyTHktKUZ4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

## Important Dates
  * **14 July 2020** Final Submissions to the Evaluation Server via Codalab
  * **21 July 2020** Paper Submission via CMT
  * **28 July 2020** Winner Announcements and Workshop Invitations
  * **28 August 2020** Workshop at ECCV


## Organisers

The workshop organisers are with the [Australian Centre for Robotic Vision](http://www.roboticvision.org)

<div class="portrait_row">
<img class="col fith portrait" src="assets/img/david.jpg"/>  
<img class="col fith portrait" src="assets/img/niko.jpg"/>
<img class="col fith portrait" src="assets/img/feras.jpg"/>
</div>
<div class="col fith caption">
      <a href="https://sites.google.com/view/davidhallcv/home">David Hall</a> <br>Queensland University of Technology
</div>
<div class="col fith caption">
      <a href="http://www.nikosuenderhauf.info">Niko SÃ¼nderhauf</a><br>Queensland University of Technology
</div>
<div class="col fith caption">
      <a href="http://www.ferasdayoub.com">Feras Dayoub</a> <br>Queensland University of Technology
</div>


<div class="portrait_row">
<img class="col fith portrait" src="assets/img/gustavo.jpg"/>
<img class="col fith portrait" src="assets/img/chunhua.png"/>
</div>
<div class="col fith caption">
      <a href="https://cs.adelaide.edu.au/~carneiro/">Gustavo Carneiro</a> <br> University of Adelaide
</div>
<div class="col fith caption">
       <a href="https://researchers.adelaide.edu.au/profile/chunhua.shen">Chunhua Shen</a> <br> University of Adelaide
</div>


<br><br>

## Sponsors
<div style="display:flex; justify-content:center;">
<a href="http://www.roboticvision.org"><img style="height:120px;" src="assets/img/acrv.png"></a>
</div>
